\documentclass{beamer}
\usepackage{xcolor} 
\usepackage{caption}
\usepackage{amsmath}
\usepackage{tikz}
\usepackage{multicol}
\usepackage{tikz-cd}
\usepackage{hyperref}

\usetheme{Boadilla}
\title{Insert Markov pun here}
\subtitle{A talk on Probabilistic Automata and Markov Chains}
\author{Aniruddha Deb}
\institute{IIT Delhi}
\date{\today}

\captionsetup[figure]{font=footnotesize,labelfont=footnotesize}

\begin{document}

\begin{frame}
\titlepage
\end{frame}

\begin{frame}
\frametitle{Stochastic vectors and stochastic matrices}
\pause
A \textbf{Stochastic Vector} $\vec{a}$ is a vector in $\mathbb{R}^n$ which satisfies the 
following conditions:
\begin{itemize}
	\item if $s \in \vec{a}$, then $0 < s < 1$
	\item the sum of all the elements of $\vec{a}$ is 1
\end{itemize}
\vspace{2em}
\pause
A \textbf{Stochastic Matrix} (aka Markov matrix) $\mathcal{S}$ is a matrix whose column vectors
are stochastic vectors. \\
\vspace{2em}
\pause
Stochastic vectors can be thought of as a form of \textbf{discrete probability distribution}: 
given a finite number of possible states, $\vec{a}$ gives the probability 
of transitioning to the $i$th state.
\end{frame}

\begin{frame}
\frametitle{A short recap of NFA's}

\begin{center}
\includegraphics[scale=0.16]{img/recap.png}
\end{center}

\end{frame}

\begin{frame}[fragile]
\frametitle{Probabilistic Automata}
A \textbf{Probabilistic Automata} (PA) generalizes the concept of a NFA, so that
the transition probabilities are given by the transition function (the transition
function for such an automata is a stochastic matrix / markov matrix)
\pause
\begin{center}
\begin{tikzcd}
                                                                                       & B \arrow[rd, "0.5" description] \arrow[ld, "0.5" description, bend right, shift right] &                                                                                                                                                       \\
A \arrow[ru, "0.6" description] \arrow[rr, "0.4" description, bend right, shift right] &                                                                                        & C \arrow[ll, "0.5" description] \arrow[lu, "0.1" description, bend right, shift right] \arrow["0.4" description, loop, distance=2em, in=315, out=45]
\end{tikzcd}
\end{center}
% line on how the state of a PA is represented by a stochastic vector
\end{frame}

\begin{frame}[fragile]
\frametitle{Modeling PA's: Markov Processes}

PA's lend themselves to being modeled by markov matrices very well. As an example,
the process in the previous slide can be modeled as follows:

\pause 
\begin{center}
\begin{columns}[onlytextwidth]
\begin{column}{0.3\textwidth}
\begin{tikzcd}
                                                                                       & B \arrow[rd, "0.5" description] \arrow[ld, "0.5" description, bend right, shift right] &                                                                                                                                                       \\
A \arrow[ru, "0.6" description] \arrow[rr, "0.4" description, bend right, shift right] &                                                                                        & C \arrow[ll, "0.5" description] \arrow[lu, "0.1" description, bend right, shift right] \arrow["0.4" description, loop, distance=2em, in=315, out=45]
\end{tikzcd}	
\end{column}
\begin{column}{0.7\textwidth}
$$
\vec{a}_A = \begin{bmatrix} 0 \\ 0.6 \\ 0.4 \end{bmatrix}
\vec{a}_B = \begin{bmatrix} 0.5 \\ 0 \\ 0.5 \end{bmatrix}
\vec{a}_C = \begin{bmatrix} 0.5 \\ 0.1 \\ 0.4 \end{bmatrix}$$
$$
\mathcal{S} = \begin{bmatrix}
0 & 0.5 & 0.5 \\
0.6 & 0 & 0.1 \\
0.4 & 0.5 & 0.4
\end{bmatrix}
$$
\end{column}
\end{columns}
\end{center}
\pause
Now, given an initial state $a$, $\mathcal{S}a$ would give the final state after
one transition. By induction, $\mathcal{S}^n a$ would give the final state after
$n$ transitions.
\end{frame}

\begin{frame}[t]\frametitle{More on Markov Matrices}
\begin{itemize}
	\item A markov matrix $\mathcal{S}$ multiplied by a stochastic vector $\vec{a}$ gives a stochastic vector
\end{itemize}
\underline{Proof:} Consider the row vector $T = \begin{bmatrix} 1 & 1 & ... & 1 \end{bmatrix}$.
This acts like a map from $\mathbb{R}^n \to \mathbb{R}$ defined as $T\vec{a} = a_1 + a_2 + ... + a_n$.
For a stochastic vector $\vec{a}$, $T\vec{a} = 1$. If we apply this map on $\mathcal{S}\vec{a}$, 
then we get 
$$\begin{bmatrix} 1 & 1 & ... & 1 \end{bmatrix} \mathcal{S} \vec{a} = \begin{bmatrix} 1 & 1 & ... & 1 \end{bmatrix} \vec{a} = 1$$
(Since every column vector of a stochastic matrix is a stochastic vector, 
$T\mathcal{S} = T$) \\
\vspace{2em}
Hence, $\vec{a^1} = \mathcal{S}\vec{a}$ is a stochastic vector. By induction, 
$\vec{a^n} = \mathcal{S}^n\vec{a}$ is also a stochastic vector. $\blacksquare$
\end{frame}

\begin{frame}[t]\frametitle{Eigenvalues and Eigenvectors of $\mathcal{S}$}
\pause
\begin{center}{\color{red}Can you find an eigenvalue of $\mathcal{S}$ by inspection?}\end{center}
More verbosely, what is an eigenvalue of a matrix, all of whose columns sum to 1?
\pause
\begin{itemize}
	\item 1 is an eigenvalue of every stochastic matrix $\mathcal{S}$
\end{itemize}
\underline{Proof:} we need to show $|\mathcal{S} - I| = 0$. Notice that since every column
of $\mathcal{S}$ sums to 1, every column of $\mathcal{S} - I$ would sum to 0. 
Hence $|\mathcal{S} - I| = 0$. $\blacksquare$\\
\vspace{1em}
% redo this! it's incorrect, as the rows don't sum to 1. Perron-Frobenius theorem
% needed
\begin{itemize}
	\item All other eigenvalues of $\mathcal{S}$ are less than 1
\end{itemize}
\underline{Proof:} Suppose there exists $\lambda > 1$ such that $\mathcal{S}\vec{a} = \lambda \vec{a}$.
let $a_L$ be the largest element of $\vec{a}$. Every entry in $\lambda\vec{a}$ can be written as 
$$a_i = \sum_{j=1}^n a_j\mathcal{S}_{ij} {\color{red}<} a_L \sum_{j=1}^n \mathcal{S}_{ij} = a_L$$
but since $\lambda a_L \in \lambda\vec{a}$ and $\lambda > 1$, we have a contradiction.
Hence, all the eigenvalues of $\mathcal{S}$ are less than 1. $\blacksquare$

\end{frame}

\begin{frame}[t]\frametitle{Analysing the steady state}

What is a steady state? When the PA reaches a state that does not change in the 
next iteration, we call it a steady state. Using a markov matrix, we can define 
it as:
$$\mathcal{S}\vec{\tau} = \vec{\tau}$$
It's easy to see that $\vec{\tau}$ is the eigenvector corresponding to the eigenvalue
1. The question then arises 

% need to do perron-frobenius theorem: reducible and irreducible markov chains,
% proving that the eigenvalue 1 has dimension 1 for an irreducible markov chain
% and hence an irreducible markov chain reaches a steady state.

\underline{Proof:} 

\end{frame}

\end{document}
